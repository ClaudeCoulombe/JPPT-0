{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPPT-0 : J'ai Pas PéTé mon budget calcul!\n",
    "\n",
    "## Génération simple de textes en français avec des modèles de Markov\n",
    "\n",
    "par Claude COULOMBE - Ph. D. / consultant en IA appliquée / Lingua Technologies inc.\n",
    "\n",
    "JPPT-0, un petit générateur de textes en français basé sur un modèle de langue (i.e. un modèle de prédiction du prochain mot) à base de ngrammes et d'une chaîne de Markov. \n",
    "\n",
    "Pour cela, il crée un index de trigrammes et de leur fréquence par un dépouillement très rapide d'un petit corpus en quelques secondes sur un micro-ordinateur ordinaire.\n",
    "\n",
    "Sur l'idée de la chaîne de Markov, un modèle prédictif ainsi constitué peut générer un texte en se basant sur le mot ou gramme qui est le successeur le plus probable de deux mots donnés. Pour démarrer on fournira les deux premiers mots (un germe) ou autrement le générateur fera un choix aléatoire. \n",
    "\n",
    "## Pourquoi?\n",
    "\n",
    "Avec JPPT-0, il est possible de créer des modèles capables de générer des textes assez bluffants, du moins amusants ou poétiques, sans avoir à entraîner des modèles d'apprentissage profond pendant des jours sur des corpus représentant une fraction importante du contenu de la Toile.\n",
    "\n",
    "GPT-2 pour Generative Pre-training Transformer) auraient été entraînés sur un corpus énorme (40 gigaoctets de textes) pendant une semaine sur une architecture comportant 32 processeurs spécialisés dans les calculs matriciels (TPU: Tensor Processor Unit). On estime les coûts de calcul du modèle comportant 1.5 milliards de paramètres à environ 60 000 dollars canadiens. Ce n’est que la pointe de l’iceberg, car on néglige tous les calculs ayant menés à sa mise au point. On estime que l'entraînement de GPT-3, le successeur de GPT-2, qui comporte 175 milliards de paramètres, aurait coûté plus de 5 millions de dollars canadiens en temps de calcul.\n",
    "\n",
    "En entraînant à faible coût JPPT-0 sur de petits corpus spécialisés, par exemples des lettres de motivation, il est relativement facile de créer de petites applications sans péter son budget calcul.   \n",
    "\n",
    "\n",
    "## À défaut d'intelligence artificielle, nous avons créé de l'intelligence superficielle!\n",
    "\n",
    "Les générateurs de texte auto-attentifs du style GPT-X (j'essaie d'éviter le mot « transformer » qui se rapporte à un dessin animé japonais et qui ne veut strictement rien dire) demeurent très limités sur le plan sémantique. Par contre, ces outils peuvent être utiles pour contrer le « syndrome de la page blanche » et générer des babillages insignifiants... Cela dit, une personne intelligente peut s'en servir en filtrant et corrigeant les idioties.\n",
    "\n",
    "Soulignons que la Francophonie a maintenant, <a href=\"https://cedille.ai/\">« Cédille »</a>, un « idiot savant » de qualité équivalente à ceux de langue anglaise. D'après mes tests assez limités, « Cédille » est visiblement meilleur en français que les GPT-X multilingues. Aussi, ses réponses son « culturellement » teintées de la culture francophone. Par exemple, il va faire des allusions au Québec, Canada, France, etc.\n",
    "\n",
    "Notons en terminant que les avancées récentes en traduction automatique neuronale, les modèles neuronaux du langage et le mécanisme d’attention sur lequel est basé l’architecture Transformer utilisée par BERT et GPT-X originent en grande partie des travaux pionniers du MILA et de l’équipe de Yoshua Bengio de l’UdeM qui ont été perfectionnés et industrialisés par Google et OpenAI.\n",
    "\n",
    "### Sources d'inspiration:\n",
    "\n",
    "Discussions toujours passionnantes avec mon ami <a href=https://recherche.umontreal.ca/nos-chercheurs/repertoire-des-professeurs/chercheur/is/in15254/>Patrick Drouin</a>, Ph.D. professeur titulaire en traduction et terminologie à l’Université de Montréal.  \n",
    "\n",
    "https://fr.wikipedia.org/wiki/Cha%C3%AEne_de_Markov\n",
    "\n",
    "https://www.nltk.org/\n",
    "\n",
    "https://www.nltk.org/book/\n",
    "\n",
    "http://stackoverflow.com/questions/18391602/what-does-generate-do-when-using-nltk-in-python\n",
    "\n",
    "http://www.mikesboyle.com/post/117202964694/python-nltk-wtf-chapter-1-notes-on-things-that\n",
    "\n",
    "http://www.gilesthomas.com/2010/05/generating-political-news-using-nltk/\n",
    "\n",
    "http://www.cs.princeton.edu/courses/archive/spr05/cos126/assignments/markov.html\n",
    "\n",
    "http://stackoverflow.com/users/55562/lakshman-prasad\n",
    "\n",
    "http://stackoverflow.com/questions/32441605/generating-ngrams-unigrams-bigrams-etc-from-a-large-corpus-of-txt-files-and-t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version avec un germe et corpus fourni avec lien vers un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code chaine de Markov!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "\n",
    "class ChaineDeMarkov(object):\n",
    "\n",
    "    def __init__(self, chemin_fichier):\n",
    "        self.cache = {}\n",
    "        self.chemin_fichier_corpus = chemin_fichier\n",
    "        self.lexique = self.lire_corpus()\n",
    "        self.taille_lexique = len(self.lexique)\n",
    "        self.cache_de_trigrammes()\n",
    "\n",
    "    def lire_corpus(self):\n",
    "        self.fichier_corpus = open(self.chemin_fichier_corpus,'r')\n",
    "        self.fichier_corpus.seek(0)\n",
    "        donnees = self.fichier_corpus.read()\n",
    "        lexique = wordpunct_tokenize(donnees)\n",
    "        return lexique\n",
    "\n",
    "    def generer_ngrammes(self, n):\n",
    "        return list(ngrams(self.lexique, n))\n",
    "\n",
    "    def cache_de_trigrammes(self):\n",
    "        for gramme1, gramme2, gramme3 in self.generer_ngrammes(3):\n",
    "            cle = (gramme1, gramme2)\n",
    "            if cle in self.cache:\n",
    "                self.cache[cle].append(gramme3)\n",
    "            else:\n",
    "                self.cache[cle] = [gramme3]\n",
    "\n",
    "    def generation_texte(self, taille=25, germe=None):\n",
    "        if (not germe) or (len(germe.split(\" \"))< 2):\n",
    "            germe = random.randint(0, self.taille_lexique-3)\n",
    "            gramme1, gramme2 = self.lexique[germe], self.lexique[germe+1]\n",
    "        else:\n",
    "            gramme1, gramme2 = germe.split(\" \")[-2:]\n",
    "        mots_generes = []\n",
    "        for i in range(taille):\n",
    "            mots_generes.append(gramme1)\n",
    "            try:\n",
    "                gramme1, gramme2 = gramme2, random.choice(self.cache[(gramme1, gramme2)])\n",
    "            except:\n",
    "                germe = random.randint(0, self.taille_lexique-3)\n",
    "                gramme1, gramme2 = self.lexique[germe], self.lexique[germe+1]\n",
    "        mots_generes.append(gramme2)\n",
    "        texte_genere = ' '.join(mots_generes)\n",
    "        texte_genere = texte_genere[0:texte_genere.rfind(\".\")+1]\n",
    "        texte_genere = re.sub(r\"\\s([.!?,;:])|\\s(['-])\\s\", r'\\g<1>\\g<2>', texte_genere)\n",
    "        return texte_genere[0].upper() + texte_genere[1:]\n",
    "\n",
    "print(\"Code chaine de Markov!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement d'un modèle Markov trigrammes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec un corpus « Le Coeur a ses raisons » de Marc Labrèche, créé en moissonnant la Toile\n",
    "\n",
    "##### Sources: \n",
    "\n",
    "https://lecoeurasesraisons.fandom.com/fr/wiki/Citations\n",
    "\n",
    "https://www.narcity.com/fr/montreal/les-20-meilleures-citations-de-criquette-rockwell-dans-le-coeur-a-ses-raisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "casr_chemin_fichier_txt = \"DATA/Marc_Labrèche.txt\"\n",
    "markov = ChaineDeMarkov(casr_chemin_fichier_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération d'un texte avec un germe de départ\n",
    "\n",
    "Note: le paramètre «taille» contrôle la taille du texte en sortie.\n",
    "\n",
    "Si le paramètre «germe» est vide ou absent, un germe sera choisi aléatoirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", Brett: Cette literie satinée a transformé mon lit en une véritable glissoire de la bouche de Doug, sans le vouloir, contre leur gré, quoi. Brett: Tu sembles tenir la forme? Brad: Brad!! Brad: Oublions nos vieilles querelles... Serrons-nous. Ils s'embrassent. Rideau. Brett: Ne vous inquiètez pas Criquette. Lorsqu'un sourire reptilien. Brett: Oui.. C'est ça?! Brett: Wow. Pardonnez-moi, Brett? Brett: Vous avez fait votre choix? Ridge: Ridge pense... Malgré un doctorat en philosophie et une maîtrise en danse africaine, je?? Doug: Je ne sais pas. Sortons nos jumelles de poches. Si pratiques lors des voyages ou des safaris photos. Ils sortent des jumelles imaginaires.\n"
     ]
    }
   ],
   "source": [
    "# Génération d'un texte aléatoire\n",
    "texte_genere = markov.generation_texte(taille=150,germe=\"Brett:\")\n",
    "texte_genere = texte_genere.replace(\" ' \",\"'\").replace(\" ’ \",\"'\").replace(\"*\",\",\").replace(\" - \",\"-\").replace('cest','ces').replace('Cest','ces')\n",
    "print(texte_genere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec un corpus de textes de « Mathieu Bock-Côté » recueillis sur le site du Journal de Montréal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbc_chemin_fichier_ = \"DATA/Mathieu_Bock-Côté.txt\"\n",
    "markov = ChaineDeMarkov(mbc_chemin_fichier_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Québec libre. Quelle sera la véritable raison du fait qu'on en arrive à la veille que cela. Après avoir compilé les études portant sur les enjeux du jour au lendemain de l'histoire politique a-t-il? La CAQ est en train de marquer une claire volonté indépendantiste suffirait-il de la loi sur la route du temps, pour rappeler que le sien sans l'évolution des prénoms américains ( Logan, Tyler, Jayden, etc.), les deux avenirs possibles de nombreux pays. Je vous donne-t-il pas naturellement les animer. Plus l'identité québécoise sans un gouvernement enthousiaste désireux de ne pas arriver ». Le sens du silence, de la droite, étrangement, la loi.\n"
     ]
    }
   ],
   "source": [
    "# Génération d'un texte avec le germe \"Québec libre\"\n",
    "texte_genere = markov.generation_texte(taille=150,germe=\"Québec libre\")\n",
    "mathieu_bot_cote = texte_genere.replace(\" ' \",\"'\").replace(\" ’ \",\"'\").replace(\"*\",\",\").replace(\" - \",\"-\").replace('cest','ces').replace('Cest','ces')\n",
    "print(mathieu_bot_cote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": Que gagnerons-nous dérobé de l'éternel a maudite. Lémec, sept personnes. Les frères de Joseph, en présence duquel ont marché avec moi; et voici, la sage-femme dit: Vous me troublez, en sorte que, le froid et la femme de son armée. Dieu se pourvoira lui-même de l'assentiment de Hamor. Le serviteur courut au-dessus de la crème et du vin, Et tu seras dégagé du serment que je ne parlerai plus que cette fois. Adam donna à Rebecca; il donna à ésaü, son père et de là que tu leur conserves la vie. Je t'ai élevé la voix de Jacob qui vinrent avec Jacob en égypte, et partirent.\n"
     ]
    }
   ],
   "source": [
    "# Génération d'un texte aléatoire - sans germe\n",
    "texte_genere = markov.generation_texte(taille=150)\n",
    "texte_genere = texte_genere.replace(\" ' \",\"'\").replace(\" ’ \",\"'\").replace(\"*\",\",\").replace(\" - \",\"-\").replace('cest','ces').replace('Cest','ces')\n",
    "print(texte_genere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec un corpus biblique en français  provenant de la bibliothèque NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisé pour générer le fichier texte_biblique.txt à partir de NLTK\n",
    "\n",
    "# texte_genese_multilingue = nltk.Text(nltk.corpus.genesis.words())\n",
    "\n",
    "# # Extraction du corpus NLTK de la version française du texte de la Genèse \n",
    "# texte_genese_francais = \" \".join(texte_genese_multilingue.tokens[121338:167454])\n",
    "\n",
    "# # Sauvegarde d'une copie sur di=sque pour assurer la compatibilité avec l'API de la fonction ChaineDeMarkov\n",
    "# with open(\"DATA/texte_biblique.txt\",'w') as fichier:\n",
    "#     fichier.write(texte_genese_francais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dieu dit: Que cherches-tu fait? La femme vit que l'un demi-sicle, et se rendit vers Pharaon. Pharaon dit à Laban: Donne-moi. Et ils firent entendre de grandes plaies Pharaon et à ta race. On fit descendre Joseph en égypte, et se présentèrent devant Joseph. Ils s'approchèrent, et il y avait du pain contre vos troupeaux, si l'entrée d'ésaü: elle enfanta un fils. Et Laban lui donna le même ordre au premier-né, que ton âme me bénisse. Isaac dit: Si vous êtes des espions.\n"
     ]
    }
   ],
   "source": [
    "markov = ChaineDeMarkov(\"DATA/texte_biblique.txt\")\n",
    "\n",
    "texte_genere = markov.generation_texte(150, \"Dieu dit\")\n",
    "texte_genere = texte_genere.replace(\" ' \",\"'\").replace(\" ’ \",\"'\").replace(\"*\",\",\").replace(\" - \",\"-\").replace('cest','ces').replace('Cest','ces')\n",
    "\n",
    "print(texte_genere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin du carnet web IPython!\n"
     ]
    }
   ],
   "source": [
    "print(\"Fin du carnet web IPython!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
